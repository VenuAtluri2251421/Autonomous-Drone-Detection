# ğŸš Autonomous Drone with Object Detection  

An **autonomous drone framework** built for Raspberry Pi, featuring real-time **YOLO-based object detection** and a modular control system.  
This repository demonstrates how drones can integrate **computer vision** for smart navigation and surveillance tasks.  

---

## ğŸ“‚ Repository Structure  

```
autonomous-drone/
â”‚â”€â”€ drone_controller.py       # Main controller for drone logic
â”‚â”€â”€ object_detection.py       # Object detection with YOLO
â”‚â”€â”€ utils/
â”‚   â””â”€â”€ camera_stream.py      # Camera streaming utility
â”‚â”€â”€ requirements.txt          # Dependencies
â”‚â”€â”€ README.md                 # Project documentation
```

---

## âœ¨ Features  

- ğŸš€ **Autonomous Flight Simulation** â€“ Takeoff, patrol, and landing logic.  
- ğŸ§  **Object Detection (YOLO)** â€“ Detects real-world objects like people, cars, animals.  
- ğŸ¥ **Live Camera Stream** â€“ Works with Raspberry Pi Camera Module or USB webcams.  
- ğŸ”— **Modular Design** â€“ Easy integration with real drone SDKs (DJI Tello, ArduPilot, PX4, etc.).  
- ğŸ“¡ **Raspberry Pi Ready** â€“ Lightweight and optimized for edge devices.  

---

## ğŸ›  Installation  

1. Clone the repository:  
   ```bash
   git clone https://github.com/<your-username>/autonomous-drone.git
   cd autonomous-drone
   ```

2. Install dependencies:  
   ```bash
   pip install -r requirements.txt
   ```

3. (Optional) Enable Raspberry Pi Camera:  
   ```bash
   sudo raspi-config
   ```

---

## ğŸš€ Usage  

Run the drone controller:  

```bash
python drone_controller.py
```

The script will:  
- Simulate drone **takeoff**  
- Begin **patrol mode**  
- Perform **object detection**  
- **Hover or land** depending on detections  

---

## ğŸ¤– Object Detection with YOLO  

This project uses **YOLO (You Only Look Once)** for real-time detection.  
To train and export your own YOLO models, refer to my other repository:  

ğŸ‘‰ [Learn YOLO in 6 Steps](https://github.com/VenuAtluri2251421/learn-yolo-in-6-steps)  

Once trained, place the exported YOLO weights in:  
```
autonomous-drone/yolo_model/
```

---

## ğŸ“¸ Example Output  

```
[DRONE] Taking off...
[DRONE] Hovering at safe altitude.
[DRONE] Starting patrol mode...
[DETECTION] Objects detected: ['person']
[DRONE] Person detected! Hovering in place.
[DRONE] Landing...
[DRONE] Drone landed successfully.
```

---

## ğŸ“Œ Notes  

- This is a **sample framework** for demonstration and prototyping.  
- Replace placeholder functions with real drone SDK calls for full automation.  
- Designed for **Raspberry Pi** but adaptable to other platforms.  

---

## ğŸ“š References  

- [YOLO Object Detection](https://github.com/VenuAtluri2251421/learn-yolo-in-6-steps)  
- [OpenCV Documentation](https://docs.opencv.org/)  
- [Drone SDKs: PX4, ArduPilot, DJI Tello]  

---

## ğŸŒŸ Future Improvements  

- Add obstacle avoidance using **LiDAR / depth cameras**.  
- Implement **GPS-based waypoint navigation**.  
- Integrate **LoRa / 5G communication** for long-range missions.  

---

## ğŸ‘¨â€ğŸ’» Author  

Built with â¤ï¸ by Venu Atluri (https://github.com/VenuAtluri2251421)
